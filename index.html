<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content=" Adaptive high-resolution mapping of air pollution with a novel implicit 3D representation approach">
  <meta name="keywords" content="satellite monitoring, air pollution, high-resolution mapping, deep learning, implicit representation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Adaptive high-resolution mapping of air pollution with a novel implicit 3D representation approach</title>

  <meta name="google-site-verification" content="wqG380jQOyUT5HIVYVvh9FR_EnEqKY2aHflQGJ_slJA" />

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>




<section class="hero" style="margin-top: 1rem;">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Adaptive high-resolution mapping <br>of air pollution with a novel <br>implicit 3D representation approach</h1>
          <!-- <h2 class="title is-2 publication-title"><span style="color: rgba(250, 66, 66, 0.988);">CVPR</span> 2025</h2> -->
          <div class="is-size-5 publication-authors">
            <!-- <span class="author-block">
              <a href="https://yxxxb.github.io/">Xubing Ye</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=8rltp9AAAAAJ&hl=zh-CN">Yukang Gan</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://xk-huang.github.io/">Xiaoke Huang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://geyixiao.com/">Yixiao Ge</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en">Ying Shan</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://andytang15.github.io/">Yansong Tang</a><sup>1</sup>
            </span> -->
            <span class="author-block">
              <a >Ting Zhang</a><sup>1</sup>
            <span class="author-block">
              <a >Bo Zheng</a><sup>1</sup>
            <span class="author-block">
              <a >Ruqi Huang</a><sup>1</sup> 
            </span>
          </div> 

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tsinghua University,</span>
            <!-- <span class="author-block"><sup>2</sup>ARC Lab, Tencent PCG,</span>
            <span class="author-block"><sup>3</sup>UC Santa Cruz</span> -->
          </div>



          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2406.12275v2"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2406.12275v2"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/height-field-sdf/implicit-representation-for-high-resolution-mapping"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <div class="column is-3 has-text-centered">
  <img src="./static/images/interpolate_start.jpg"
       class="interpolation-image"
       alt="Interpolate start reference image."/>
  <p>Start Frame</p>
</div> -->


<section class="section" style="margin-top: -4rem;">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <h2 class="title is-3">TL;DR</h2> -->
        <div class="content has-text-justified">
          1. We propose HF-SDF, the noval approach to conduct adaptive high-resolution mapping using implicit representation. 
          By fully utilizing the transferable, geometry-aware implicit representation, our method achieves strong transferability by eliminating dependencies on localization-specific predictors, mitigates resolution constraints through continuous modeling, and provides a more accurate and adaptable framework for high-resolution pollution mapping.
          <br>2. HF-SDF demonstrates the ability to understand air pollution patterns through continuous reconstructing using noisy, sparse, and incomplete observations.
          <br>3. HF-SDF presents a promising way to alleviate data assimulation challenges and enable more scalable multi-modal applications like Earth System Models (ESMs).

        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/voco/Figure_1.jpg"
       class="interpolation-image"
       alt="Interpolate start reference image."/>
      <h2 class="subtitle has-text-centered">
        <br>Model framework. (a)–(d) illustrate the stepwise modeling approach. Specifically, (a.1), (b), (c.1), and (d) represent the high-resolution mapping pipeline for single-day measurements, while (a.2), (b), (c.2), and (d) correspond to the high-resolution mapping pipeline for multi-day measurements.
        <!-- (a) VLMs are bottlenecked by the limited context window when processing high-resolution images and videos. 
        (b) Previous methods compress vision tokens with external modules with substantial loss.
        (c) Illustration of <b>VoCo-LLaMA</b>, which empowers LLM to compress vision tokens and understand compressed tokens via intrinsic token distillation. -->
      </h2>
    </div>
  </div>
</section>


<section class="section" style="margin-top: -2rem;">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- <p>
            We present the first method capable of photorealistically reconstructing a non-rigidly
            deforming scene using photos/videos captured casually from mobile phones.
          </p>
          Vision-Language Models (VLMs) have achieved remarkable success in various multi-modal tasks, but they are often bottlenecked by the limited context window and high computational cost of processing high-resolution image inputs and videos. 
          Vision compression can alleviate this problem by reducing the vision token count.
          Previous approaches compress vision tokens with external modules and force LLMs to understand the compressed ones, leading to visual information loss.
          However, the LLMs' understanding paradigm of vision tokens is not fully utilised in the compression learning process. -->
          <!-- We propose VoCo-LLaMA, the first approach to compress vision tokens using LLMs. 
          We strive to fully utilize the LLMs' understanding paradigm of vision tokens during the compression learning process.
          By introducing <b>V</b>isi<b>o</b>n <b>Co</b>mpression tokens during the vision instruction tuning phase and leveraging attention distillation, our method distill how LLMs comprehend vision tokens into their processing of VoCo tokens.
          VoCo-LLaMA facilitates effective vision compression and improves the computational efficiency during the inference stage.
          Specifically, our method achieves minimal performance loss with a compression ratio of <b>576 x</b>, resulting in up to 94.8% fewer FLOPs and 69.6% acceleration in inference time. 
          Furthermore, through continuous training using time-series compressed token sequences of video frames, VoCo-LLaMA demonstrates the ability to understand temporal correlations, outperforming previous methods on popular video question-answering benchmarks.
          Our approach presents a promising way to unlock the full potential of VLMs' contextual window, enabling more scalable multi-modal applications. -->
          Mapping air pollution at high spatial resolution is essential for understanding, managing, and mitigating the adverse impacts of air pollution. 
          The current approaches for air pollution monitoring (e.g., ground station, satellite) suffer from limited spatial coverage and resolution. 
          Artificial intelligence (AI) has shown great potential to resolve these issues. However, regarding low-quality labeled data and uneven spatial coverage, AI-based methods with transferability for air pollution monitoring are still in their infancy. 
          Here, we introduce an innovative 3D implicit representation, dubbed Height-Field Signed Distance Function (HF-SDF), to reconstruct air pollution concentration maps at spatial resolutions of desire, which can achieve both extensive spatial coverage and fine-scale results with powerful transferability. 
          Our proposed HF-SDF, which integrates a deep network with a geometric constraint, can produce adaptive high-resolution air pollution maps, which are robust to noisy and locally incomplete data.Our framework can learn a continuous, transferable 3D generative model of HF-SDF, 
          by employing an auto-decoder network structure, allowing for the comprehensive reconstruction of a broad spectrum of air pollutants. 
          The evaluation based on two types of air pollution data, including aerosol concentration maps and satellite observations, reaches accuracy rates of 96% and 91%, respectively. 
          HF-SDF reveals immense promise in advancing air pollution monitoring by offering insights into the spatial heterogeneity of pollution distributions. 
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    
  </div>
</section>


<section class="section" style="margin-top: -2rem;">
  <div class="container is-max-desktop">

    <!-- Animation. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Concept illustration of HF-SDF</h2>
        
        <div class="columns is-vcentered">
          <!-- 图片列 -->
          <div class="column is-half">
            <div class="content has-text-centered">
              <img src="./static/voco/Figure_2.jpg"
              class="interpolation-image"
              alt="Interpolate start reference image."
              style="width: 100%; height: auto;"/>
            </div>
          </div>
          
          <!-- 视频列 -->
          <div class="column is-half">
            <div class="content has-text-centered">
              <video controls style="width: 100%; height: auto; background: #000;">
                <source src="./static/voco/demo.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
        
        <!-- 将subtitle统一放在外层 -->
        <div class="columns">
          <div class="column is-half has-text-centered">
            <h2 class="subtitle">
              Illustration of the HF-SDF design.
            </h2>
          </div>
          <div class="column is-half has-text-centered">
            <h2 class="subtitle">
              Demonstration Video
            </h2>
          </div>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>



<section class="section" style="margin-top: -2rem;">
  <div class="container is-max-desktop">


    <!-- Animation. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Adaptive High-Resolution Mapping on TAP</h2>
        <!-- <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div> -->
        <div class="content has-text-justified">
          Reconstruction of PM2.5 distribution in central China. 
          In (a), the TAP PM2.5 distribution within China is illustrated at a resolution of 10 km on November 3rd, 2023. 
          For panels (b), (c), and (d), the upper images depict the TAP PM2.5 distribution in Central China, 
          Hubei Province, and Wuhan City, respectively, at a 10 km resolution. 
          The lower images provide detailed patterns of the estimated PM2.5 distribution in the corresponding areas 
          of Central China, Hubei Province, and Wuhan City.
        </div>
        <div class="content has-text-centered">
          <img src="./static/voco/Figure_3.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."
          style="width: 80%; height: auto;"/> 
        </div>
        <div class="content has-text-justified">
          Assessment of HF-SDF for ultra-high resolution mapping from sparse observations. 
          In (a), the PM2.5 distribution around the Sichuan Basin from the TAP 1km dataset was downscaled at various scales, where DS 5km, DS 10km, DS 20km, DS 30km, DS 40km illustrate downsampled inputs at resolutions of 5km, 10km, 20km, 30km, and 40km, respectively. Panel (b) illustrates our reconstruction results at a resolution of 1km, inferred from TAP 1km, DS 5km, DS 10km, DS 20km, DS 30km, and DS 40km, respectively. Panel (c) illustrates the difference between our 1km resolution reconstructions and the data from TAP 1km. Chart (d) shows two groups of R and IOA: Ours 1km vs. TAP 1km and Ours vs. Downsampled Input. Chart (e) illustrates two groups of distribution of reconstruction error: Ours 1km vs. TAP 1km and Ours vs. Downsampled Input.
        </div>
        <div class="content has-text-centered" style="margin-top: -1rem;">
          <img src="./static/voco/Figure_4.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."
          style="width: 80%; height: auto;"/> 
        </div>
        <div class="content has-text-justified">
          High-resolution air pollution mapping with varying unmeasured areas. 
          Panels (a) to (e) show reconstruction outcomes for maps with unmeasured areas 
          of radii 0.05°, 0.15°, 0.25°, 0.35°, and 0.45° respectively. 
          GAP1 to GAP5 denote these unmeasured areas. Each panel displays (left to right): the input map, high-resolution output, complete map (GT), and bias visualization (CDF). See Supporting Information Appendix B.3 for more details.
        </div>
        <!--/ Re-rendering. -->
        <div class="content has-text-centered" style="margin-top: -1rem;">
          <img src="./static/voco/Figure_6.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."
          style="width: 80%; height: auto;"/> 
        </div>
        <div class="content has-text-justified">
          We utilize the coded map network to evaluate the generalization capability of HF-SDF within trained regions, as well as its transferability to entirely unseen locations and different air pollutants.
           Details regarding the dataset used for model training and testing, as well as model performance, are summarized in Table 1. 
          The training set comprises PM2.5 data (TAP) collected from 2021 to 2022 in six locations: Chengdu (CD), Bazhou (BZ), Taiyuan (TY), Changsha (CS), Xining (XN), and Longnan (LN), each covering a geographic area of 10&deg; &times; 10&deg;. For additional details, refer to the Supporting Information (Table S7). To address concerns of homogeneity, the training dataset includes 1080 instances of concentration maps, randomly sampled from 180 days between 2021 and 2022 for each location. 
          Subsequently, test sets, which include different regions, times, and air pollutants, were utilized to assess the model's generalization capability and transferability.
        </div>
        <div class="content has-text-centered" style="margin-top: -1rem;">
          <img src="./static/voco/Figure_5.png"
          class="interpolation-image"
          alt="Interpolate start reference image."
          style="width: 80%; height: auto;"/> 
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>

<section class="section" style="margin-top: -2rem;">
  <div class="container is-max-desktop">


    <!-- Animation. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Satellite Observations Mapping</h2>
        <div class="content has-text-justified">
          Satellites provide a global perspective on air quality monitoring; however, limitations such as low spatial resolution and unexpected data gaps reduce data availability. 
          As discussed above, HF-SDF facilitates the continuous reconstruction of air pollution data despite these challenges, enabling effective reconstruction of satellite data.
          Here, we take the TROPOMI NO2 column as an example to demonstrate the effectiveness of HF-SDF for satellite observations mapping.
        </div>
        <div class="content has-text-centered">
          <img src="./static/voco/Figure_7.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."
          style="width: 90%; height: auto;"/> 
        </div>
        <div class="content has-text-justified">
          Experiments on TROPOMI. Panel (a) illustrates the projection of satellite data alongside our continuous reconstruction at various resolutions: 
          (a.1) presents raw NO2 data from TROPOMI, 
          (a.2) showcases our reconstruction projected at a resolution of 10 km, 
          (a.3) displays our reconstruction projected at a resolution of 2 km, 
          (a.4) exhibits our reconstruction projected at a resolution of 1 km, 
          and (a.5) visualizes the reconstructed 3D concentration surface. 
          Panel (b) depicts NO2 concentration maps over China on the 10-day scale. 
          (b.1) features averaged NO2 concentration maps over 10 continuous days from May 1st to 10th, 2018, 
          while (b.2) presents the corresponding reconstruction. Reconstruction on a single day can be found in Supporting Information Figure S6.
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>




<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{ye2024voco,
    author    = {Ye, Xubing and Gan, Yukang and Huang, Xiaoke and Ge, Yixiao and Shan, Ying and Tang, Yansong},
    title     = {{VoCo-LLaMA: Towards Vision Compression with Large Language Models}},
    journal   = {arXiv preprint arXiv:2406.12275},
    year      = {2024},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p> 
            Contact: 
            <a href="mailto:zhangt2112@gmail.com">zhangt2112@gmail.com</a>. 
            <!-- <a href="mailto:yxb_tongji@163.com">yxb_tongji@163.com</a>.<br> -->
            This website is adapted from <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
